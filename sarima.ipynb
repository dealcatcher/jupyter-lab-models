{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading\n",
    "This section imports the required libraries and loads the dataset into a pandas DataFrame. The dataset is the foundation for all subsequent preprocessing and analysis steps. we will install all the librabies that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.6-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.5 kB)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.9.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting numpy<3,>=1.22.3 (from statsmodels)\n",
      "  Using cached numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting scipy!=1.9.2,>=1.8 (from statsmodels)\n",
      "  Using cached scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Using cached patsy-1.0.2-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/ayushghimire/Library/Python/3.9/lib/python/site-packages (from statsmodels) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ayushghimire/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.60.2-cp39-cp39-macosx_10_9_universal2.whl.metadata (113 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.3.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/ayushghimire/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Downloading statsmodels-0.14.6-cp39-cp39-macosx_11_0_arm64.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m964.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hUsing cached pandas-2.3.3-cp39-cp39-macosx_11_0_arm64.whl (10.8 MB)\n",
      "Using cached matplotlib-3.9.4-cp39-cp39-macosx_11_0_arm64.whl (7.8 MB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached contourpy-1.3.0-cp39-cp39-macosx_11_0_arm64.whl (249 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.60.2-cp39-cp39-macosx_10_9_universal2.whl (2.9 MB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl (64 kB)\n",
      "Using cached numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\n",
      "Using cached patsy-1.0.2-py2.py3-none-any.whl (233 kB)\n",
      "Using cached pillow-11.3.0-cp39-cp39-macosx_11_0_arm64.whl (4.7 MB)\n",
      "Using cached pyparsing-3.3.2-py3-none-any.whl (122 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
      "Using cached tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Installing collected packages: pytz, tzdata, pyparsing, pillow, numpy, kiwisolver, importlib-resources, fonttools, cycler, scipy, patsy, pandas, contourpy, statsmodels, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.60.2 importlib-resources-6.5.2 kiwisolver-1.4.7 matplotlib-3.9.4 numpy-2.0.2 pandas-2.3.3 patsy-1.0.2 pillow-11.3.0 pyparsing-3.3.2 pytz-2025.2 scipy-1.13.1 seaborn-0.13.2 statsmodels-0.14.6 tzdata-2025.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install statsmodels pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣ Loading & Saving Data\n",
    "\n",
    "### `pd.read_csv()` — Load data\n",
    "Reads a CSV file into a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./US_Regional_Sales_Data.csv\", encoding='latin1')\n",
    "\n",
    "\n",
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2️⃣ Data filteration \n",
    "\n",
    "\n",
    "### 1.1 Droping all the columns that are not required\n",
    " - here we will drop all the location related location , except the country and city \n",
    " - i have to also removed all proof related info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[ \"ï»¿OrderNumber\",\"WarehouseCode\",\"ShipDate\",\"DeliveryDate\",\"_SalesTeamID\",\"_CustomerID\",\"_StoreID\",\"_ProductID\",])\n",
    "df_date = pd.to_datetime(df['OrderDate'])\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the data type of discounted price and actual price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Indexing the data \n",
    "\n",
    "- we will index the \"Created\" columns into a index\n",
    "- The created is of String type , so we need to convert it to datetime type\n",
    "- The index we have created is type of index not a datetimeindex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "df1.set_index(\"OrderDate\", inplace=True)\n",
    "df1.index = pd.to_datetime(df1.index)\n",
    "df1.resample(\"ME\").mean(numeric_only=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 FINAL - Data information \n",
    "- we have two differnet data now , \"DF\" where all discounted products information is collected\n",
    "- **df1** - where we have index created for the datetime index.\n",
    "- 7 days rollings statics and 30 days rolling statatics will be used , where index will helped us  or basically **df1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3️⃣Exploratory Price and Discount Analysis\n",
    "\n",
    "This section performs exploratory data analysis to examine the relationship between product prices, discounts, and sales channels over time.\n",
    "\n",
    "First, the order date is converted to a datetime format, allowing temporal analysis. Price-related columns are cleaned by removing thousand separators and converting the values to numeric format to ensure accurate mathematical operations.\n",
    "\n",
    "The analysis then visualizes key relationships using scatter plots and box plots:\n",
    "\n",
    "- The relationship between order date and unit price is examined to identify temporal trends and price dispersion over time.\n",
    "- Discounts applied over time are visualized to observe potential promotional patterns and seasonal effects.\n",
    "- The relationship between unit price and unit cost i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# extract year\n",
    "df[\"year\"] = pd.to_datetime(df[\"OrderDate\"]).dt.year\n",
    "df[\"Unit Price\"] = (\n",
    "    df[\"Unit Price\"]\n",
    "    .str.replace(\",\", \"\", regex=False)\n",
    "    .astype(float)\n",
    ")\n",
    "df[\"Unit Cost\"] = (\n",
    "    df[\"Unit Cost\"]\n",
    "    .str.replace(\",\", \"\", regex=False)\n",
    "    .astype(float)\n",
    ")\n",
    "df[\"OrderDate\"] = pd.to_datetime(df[\"OrderDate\"], format=\"%d/%m/%y\")\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(26, 30))\n",
    "fig.suptitle(\"Price & Discount Analysis\", fontsize=32)\n",
    "\n",
    "# ---------------- Plot 1: Year vs Unit Price ----------------\n",
    "axes[0, 0].scatter(df[\"OrderDate\"], df[\"Unit Price\"], alpha=0.3)\n",
    "axes[0, 0].set_title(\"Year vs Unit Price\", fontsize=18)\n",
    "axes[0, 0].set_ylabel(\"Unit Price\")\n",
    "\n",
    "# ---------------- Plot 2: Date vs Discount Applied ----------------\n",
    "axes[0, 1].scatter(df[\"OrderDate\"], df[\"Discount Applied\"], alpha=0.3)\n",
    "axes[0, 1].set_title(\"Order Date vs Discount Applied\", fontsize=18)\n",
    "axes[0, 1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# ---------------- Plot 3: Unit Price vs Unit Cost ----------------\n",
    "axes[1, 0].scatter(df[\"Unit Price\"], df[\"Unit Cost\"], alpha=0.3)\n",
    "axes[1, 0].set_title(\"Unit Price vs Unit Cost\", fontsize=18)\n",
    "axes[1, 0].set_xlabel(\"Unit Price\")\n",
    "axes[1, 0].set_ylabel(\"Unit Cost\")\n",
    "\n",
    "# ---------------- Plot 4: Discount vs Sales Channel (BOXPLOT) ----------------\n",
    "df.boxplot(\n",
    "    column=\"Discount Applied\",\n",
    "    by=\"Sales Channel\",\n",
    "    ax=axes[1, 1]\n",
    ")\n",
    "axes[1, 1].set_title(\"Discount Applied by Sales Channel\", fontsize=18)\n",
    "axes[1, 1].set_xlabel(\"Sales Channel\")\n",
    "axes[1, 1].set_ylabel(\"Discount Applied\")\n",
    "\n",
    "plt.suptitle(\"\")  # remove pandas auto-title\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Checking seasonlaity and pattern \n",
    " - while averaging the discounted prices base on the montly there was some difference betwe_en the discounted_percent average \n",
    " - **1st problem** - There was difference between the averaging for the **df_low** and **df_high** .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"OrderDate\"] = pd.to_datetime(df[\"OrderDate\"], format=\"%d/%m/%y\")\n",
    "\n",
    "\n",
    "\n",
    "yearly_low = df.groupby(df[\"OrderDate\"].dt.month)[\"Discount Applied\"].mean()\n",
    "yearly_low.plot(kind=\"bar\", title=\"Average Discount % per Month (Price ≤ 1000)\", figsize=(10, 6))\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Average Discount %\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization after removing some noises \n",
    "As we have remove the dat from year 2016 to 2022 , now we have the data from 2023 to 2025 , for which we will check the seasolity pattern. Furthermore , for the Sarima model,, we just need that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"OrderDate\"] = pd.to_datetime(df[\"OrderDate\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "yearly_low = df.groupby(df[\"OrderDate\"].dt.month)[\"Discount Applied\"].mean()\n",
    "yearly_low.plot(kind=\"bar\", title=\"Average Discount % per Month (Price ≤ 1000)\", figsize=(10, 6))\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Average Discount %\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = df[df['OrderDate'].dt.year == 2018]\n",
    "df_2019 = df[df['OrderDate'].dt.year == 2019]\n",
    "df_2020 = df[df['OrderDate'].dt.year == 2020]\n",
    "\n",
    "yearly_2018 = df_2018.groupby(df_2018[\"OrderDate\"].dt.month)[\"Discount Applied\"].mean()\n",
    "yearly_2019 = df_2019.groupby(df_2019[\"OrderDate\"].dt.month)[\"Discount Applied\"].mean()\n",
    "yearly_2020 = df_2020.groupby(df_2020[\"OrderDate\"].dt.month)[\"Discount Applied\"].mean()\n",
    "\n",
    "\n",
    "df_years = pd.DataFrame({\n",
    "    \"2018\": yearly_2018,\n",
    "    \"2019\": yearly_2019,\n",
    "    \"2020\": yearly_2020\n",
    "})\n",
    "\n",
    "\n",
    "df_years.plot(\n",
    "    kind=\"bar\",\n",
    "    figsize=(12, 6),\n",
    "    title=\"Average Discount(price<1000) % per Month (2023–2025)\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Average Discount %\")\n",
    "plt.legend(title=\"Year\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for year in df_years.columns:\n",
    "    plt.plot(\n",
    "        df_years.index,\n",
    "        df_years[year],\n",
    "        marker=\"o\",\n",
    "        label=year\n",
    "    )\n",
    "\n",
    "plt.title(\"Average Discount % per Month (2023–2025)\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Average Discount %\")\n",
    "plt.xticks(range(1, 13))\n",
    "plt.legend(title=\"Year\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weeknd and weekdays \n",
    "\n",
    "1️⃣ Make sure your date column is datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"OrderDate\"] = pd.to_datetime(df[\"OrderDate\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2️⃣ Create a weekday / weekend column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"day_type\"] = df[\"OrderDate\"].dt.dayofweek.apply(\n",
    "    lambda x: \"Weekend\" if x >= 5 else \"Weekday\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3️⃣ Compare Weekday vs Weekend (mean example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"day_type\")[\"Unit Price\"].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4️⃣ Visualization options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(\n",
    "    column=\"Unit Price\",\n",
    "    by=\"day_type\",\n",
    "    figsize=(8, 5)\n",
    ")\n",
    "plt.title(\"Unit Price: Weekday vs Weekend\")\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"Day Type\")\n",
    "plt.ylabel(\"Unit Price\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"OrderDate\"] = pd.to_datetime(df[\"OrderDate\"])\n",
    "df_ts = df.set_index(\"OrderDate\")\n",
    "\n",
    "# daily average discount\n",
    "daily_discount = df_ts[\"Discount Applied\"].resample(\"D\").mean()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "daily_discount.plot()\n",
    "plt.title(\"Daily Average Discount Percentage\")\n",
    "plt.ylabel(\"Discount %\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling mean (smooths noise)\n",
    "- If peaks repeat every ~7 days → weekly cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_discount.rolling(window=7).mean.plot(figure=(12, 4))\n",
    "plt.title(\"7-days Rolling Average of discounts over time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4️⃣ Autocorrelation (MOST IMPORTANT)\n",
    "- This is the main statistical tool for cycle detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "plot_acf(daily_discount.dropna(), lags=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal decomposition (clear cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "decomposition = seasonal_decompose(\n",
    "    daily_discount.dropna(),\n",
    "    model=\"additive\",\n",
    "    period=7   # try 7, 30, or 365\n",
    ")\n",
    "\n",
    "decomposition.plot()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
